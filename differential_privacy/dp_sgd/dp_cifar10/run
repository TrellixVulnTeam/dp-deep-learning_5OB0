#!/bin/bash
#----------------------------------------------------
# Sample Slurm job script
#   for TACC Stampede2 KNL nodes
#
#   *** Serial Job on Normal Queue ***
# 
# Last revised: 20 Oct 2017
#
# Notes:
#
#   -- Copy/edit this script as desired.  Launch by executing
#      "sbatch knl.serial.slurm" on a Stampede2 login node.
#
#   -- Serial codes run on a single node (upper case N = 1).
#        A serial code ignores the value of lower case n,
#        but slurm needs a plausible value to schedule the job.
#
#   -- For a good way to run multiple serial executables at the
#        same time, execute "module load launcher" followed
#        by "module help launcher".

#----------------------------------------------------

#SBATCH -J train           # Job name
#SBATCH -o train.o%j       # Name of stdout output file
#SBATCH -e train.e%j       # Name of stderr error file
#SBATCH -p gpu          # Queue (partition) name
#SBATCH -N 1               # Total # of nodes (must be 1 for serial)
#SBATCH -n 1               # Total # of mpi tasks (should be 1 for serial)
#SBATCH -t 05:30:00        # Run time (hh:mm:ss)


# Other commands must follow all #SBATCH directives...
module load gcc/4.9.3 cuda/8.0 cudnn/5.1 python/2.7.12
module load tensorflow-gpu/1.0.0
module list
pwd
date

# Launch serial code...

python dp_cifar10.py --save_path ../results_cifar \
                     --num_training_steps 1500  \
                     --projection_dimensions 0  \
                     --num_conv_layers 2  \
                     --accountant_type Moments \
                     --sigma 0 \
                     --eval_steps 100 \
                     --transfer_learn True \
                     --transfer_checkpoint ../results_cifar_100/m_18-11-29-15-44_aAmortized_b100_lr0.05_eps0.0_delta1e-05/ \
                     --optimizer momentum \
                     

# ---------------------------------------------------
